{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2e1dfd2a-7f57-e932-5858-a1bee4409bb1",
    "_uuid": "0d1fc1d59e6ae696fce6f90eba96bdf7f9de220a"
   },
   "source": [
    "## Predicting whether a tissue sample is a tumor or normal from miRNA expression data using bagging support vector machines\n",
    "#The code is forked and only slighlty modified from https://www.kaggle.com/thomasnelson/predicting-if-sample-is-tumor-bagsvm, I just tried to fit it more to what I encounter in day-to-day work. All credits to the original poster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e1dc69f4-e635-2add-56a1-4707cf840c10",
    "_uuid": "62e91545a233f39c0ef3e9ff8b666ab7adbd4133"
   },
   "source": [
    "### Import modules and the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "_cell_guid": "a0cd69ca-9cd5-a033-9f5a-b9e410db21a2",
    "_uuid": "ef5a945bf8d0fa0a50487a0e0deafd0ac08e5277",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_cell_guid": "6f676988-1f02-eb45-950c-7e0b3212a4aa",
    "_uuid": "7f69552b27f8016e4798d7aace9c07a7e29fa71c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../input/cervical.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6af4bdaa-2ca8-d8b5-9939-07293bd3ee70",
    "_uuid": "1ff6c8d97bbe706b7222c6c6d06e8d8bc63975e4"
   },
   "source": [
    "### Take a look at the top of the data, we have 714 features and 58 samples, plus a column of miRNA names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "9a02acf3-6b8e-fb2c-1173-3aba240bf4fc",
    "_uuid": "67e80ec351b6a63c9a92ae5aef3ed752a480654a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a11aac11-91b5-ed0f-8ad0-18b626a4e6d5",
    "_uuid": "b5eb30c923db81270650125c4d3837295adab40c"
   },
   "source": [
    "### Let's look at the library sizes (total read counts per sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "d9514702-5493-3b86-0818-a2bb272b7eea",
    "_uuid": "308d13a1e4e06c0c904784c5df530e247428db6f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes = data.sum(numeric_only=True)\n",
    "sizes.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a870f703-242f-1448-6f3b-9cd3a309423f",
    "_uuid": "e02426f553b207ac88c2a82fa9dc49ab8987ef39"
   },
   "source": [
    "### Normalization\n",
    "\n",
    "Our library sizes are very different.  Standard practice is to use some normalization method.\n",
    "\n",
    "Here I use the normalization method of counts per milion (CPM).  We divide each count by the library size to give the proportion of total reads for each gene, then multiply by 1 million to get counts per 1 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "80b33e97-00d0-f286-dbfd-58535029d0a7",
    "_uuid": "95514aaabf61a0e4e26f2c2a98fcb453d98b9b16",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID = data.ID\n",
    "data = data.drop('ID', 1)\n",
    "sums = data.sum()\n",
    "cpm = (data.div(sums))*1000000\n",
    "cpm.insert(loc=0, column='ID', value=ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_cell_guid": "07a5a1bc-342b-b683-88cb-f014f522b0c5",
    "_uuid": "d58b4da372f85558056321f90fc86937b1a56176",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(cpm.shape)\n",
    "cpm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_cell_guid": "9d20dfe5-5787-67ff-5ed0-953a6685d380",
    "_uuid": "0c1807403507303ac05b50dcbaec7f044a8d33d9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes = cpm.sum(numeric_only=True)\n",
    "sizes.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b7d537b1-8baf-cd5f-1670-f6bfb55fddfc",
    "_uuid": "c7cc2475021cf1998bc3a295d29f4789c417108b"
   },
   "source": [
    "### Here I re-format the data into a form suitable for input into the machine learning algorithm (put smples as rows and features as columns and create a vector of class labels for scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_cell_guid": "b81ff7a4-545d-43fa-bb65-854b74385c40",
    "_uuid": "db688ff751e49d281d57c089fa18ceadfcc439ec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpm = cpm.transpose()\n",
    "cpm = np.array(cpm[1:])\n",
    "class_labels = np.array([\"normal\"]*29 + [\"tumor\"]*29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_cell_guid": "b89edb87-472d-41c5-4ade-c9e38e54b837",
    "_uuid": "da9fea09b0ce084a2e7932369a51828e1e007342",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_cell_guid": "a0bbb40d-c37b-639d-6540-b9263c13c382",
    "_uuid": "02cd220686041c7cf3423b67800e53a060a597c7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca15a773-e6be-e4dc-86f1-23ed15101d9c",
    "_uuid": "06b4c6467a98bc57c8e023da52900f85969b732a"
   },
   "source": [
    "### Now we need to scale the data, that prevents the really highly expressed miRNA's from overwhelming influence on the model.  We get a warning about converting data type but thats okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_cell_guid": "2c90a6cc-c8a5-7e6d-ccaf-c6d945111b76",
    "_uuid": "57275bfcbc492756706774d95eaedd8026da037d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc_cpm = StandardScaler()\n",
    "cpm = sc_cpm.fit_transform(cpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_cell_guid": "95ace64d-71f5-887e-3746-77ec864aa0a1",
    "_uuid": "1990ee83c657eb7f22027a840dc7d21ae2d8180b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cpm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9c768151-21c9-1712-42a6-5d60d97a5fee",
    "_uuid": "c6b881288535cc19b89860b50e593be944930dac"
   },
   "source": [
    "### Now we'll use support vector machines with a linear kernel to create a classifier.  Here I use bagging (bootstrap aggregating), an ensemble method, to avoid overfitting a small data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_cell_guid": "e9344ff5-1962-c0d7-f4bf-d4e59115eef3",
    "_uuid": "18e2578c5ec6070c8a51acd5adf279c0199f7bb8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import svm\n",
    "svc = svm.SVC(kernel='linear', C=1.0)\n",
    "\n",
    "#Set a RANDOM_STATE to use for Bagging and cross validation\n",
    "RANDOM_STATE=123454321\n",
    "\n",
    "classifier = BaggingClassifier(base_estimator = svc, n_estimators = 10, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fc02c8e1-866d-41a2-8c7e-cb918a2ad668",
    "_uuid": "3604fa65ef4556003e5644b85a70ca71fdc2fe37"
   },
   "source": [
    "**10-fold Cross-validation by explicitly calling the StratifiedKFold method to control the random_state param.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_cell_guid": "9d820b95-7ef4-48b4-8c1d-0cf2d1c6909f",
    "_uuid": "33119f76bdb5dc1ac7651b2b6ce37bae9cf4e29b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "cv=StratifiedKFold(n_splits=10, random_state=RANDOM_STATE)\n",
    "scores = cross_val_score(classifier, cpm, class_labels, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3ca38921-4d35-b9c3-8d5c-b999d97600aa",
    "_uuid": "b054aa31ad199d60b75adabcf4194a49627073bf"
   },
   "source": [
    "The score is the mean of all scores in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_cell_guid": "1998ddca-5326-1efc-bfab-1f4ba4ae1026",
    "_uuid": "a439cde17e04016ec5c32595156c0de38c7f8a08",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"10-Cross validated Prediction Accuracy: {}%\".format(scores.mean()*100))"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
